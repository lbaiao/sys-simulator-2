p_max = p_max - 30
ENVIRONMENT_MEMORY = 2
MAX_NUMBER_OF_AGENTS = 3
REWARD_PENALTY = 1.5
N_STATES_BINS = 100
MAX_STEPS = 12000
STEPS_PER_EPISODE = 50
REPLAY_INITIAL = int(1E3)
ACTOR_LEARNING_RATE = 3E-5
CRITIC_LEARNING_RATE = 3E-4
HIDDEN_SIZE = 256
N_HIDDEN_LAYERS = 5
BATCH_SIZE = 128
REPLAY_MEMORY_SIZE = int(1E4)
EXPLORATION = 'ou'
REPLAY_MEMORY_TYPE = 'standard'
C = 2  # C constant for the improved reward function
CHANNEL_RND = True
noise_power = noise_power - 30

